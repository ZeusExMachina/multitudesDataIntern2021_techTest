{"ggplot2": [{"comment_id": "MDEyOklzc3VlQ29tbWVudDE4MDY0MTQ=", "comment_author": "hadley", "comment_created_date": "2020-08-15T11:32:54Z", "comment_text": "Would you mind writing a test case for this too please?"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE4OTk4ODA=", "comment_author": "hadley", "comment_created_date": "2020-08-25T13:40:15Z", "comment_text": "Shouldn't you be able to test this one without creating output plots?  I think you should be able to test the output of ggplot_build, or am I missing something?"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MDA0MzQ=", "comment_author": "kohske", "comment_created_date": "2020-08-25T14:42:12Z", "comment_text": "Shouldn't you be able to test this one without creating output plots? \u00a0I think you should be able to test the output of ggplot_build, or am I missing something?\n\nI got it. The output plots are not necessary.\nBut I think the output of ggplot_build is incomplete.\nThe output of ggplot_gtable in print.ggplot should be ideal. But\nin that case, the numbering of grob object (e.g., 305 of\ngTree[GRID.gTree.305]) must be ignored.\nhere is an example of the testing:\ngg_test_taker <- function(p) list(data = (d <- ggplot_build(p)), grobs\n= ggplot_gtable(p, d))\n\ngg_examiner <- function(o1, o2) {\n    stopifnot(all.equal(o1$data, o2$data))\n    # test identity of grobs ignoring numbering\n    # stopifnot(all.equal.grob(o1$grobs, o2$grobs))\n}\n\np <- qplot(1:3,1:3,colour=1:3)\n\no1 <- gg_test_taker(p)\no2 <- gg_test_taker(p)\n\ngg_examiner(o1, o2)\n\nDo you have any idea to test equality of two grobs?"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MDA1MzI=", "comment_author": "hadley", "comment_created_date": "2020-08-25T14:50:31Z", "comment_text": "For anything that you can only test on the grob level, I think we want images.  For everything else, you should be able to test based output of ggplot_build."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE3NjMyNzg=", "comment_author": "hadley", "comment_created_date": "2020-08-09T13:34:05Z", "comment_text": "Could you create a test case for this?  I think it should probably save a png in the tests directory, so git will alert if there are any changes."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE3ODc3OTg=", "comment_author": "kohske", "comment_created_date": "2020-08-12T02:21:29Z", "comment_text": "Could you please tell me where to put the test code?\ninst/test? and output plot should be in the same directory?\nhere is a simple test code, so if you merge the bugfix and put this anywhere in the repository, I can follow your way of testing in future.\ndf <- data.frame(x=1:6, y=1:6, f=gl(2,3))\np1 <- ggplot(df, aes(x, y)) + geom_point() + opts(aspect.ratio=3)\np2 <- ggplot(df, aes(x, y)) + geom_point() + facet_wrap(~f) + opts(aspect.ratio=3)\np3 <- ggplot(df, aes(x, y)) + geom_point() + facet_grid(.~f) + opts(aspect.ratio=3)\n\nggsave(\"aspect_ratio_facet_null.pdf\", p1)\nggsave(\"aspect_ratio_facet_wrap.pdf\", p2)\nggsave(\"aspect_ratio_facet_grid.pdf\", p3)\n\nthanks."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE4MDU5Mjg=", "comment_author": "hadley", "comment_created_date": "2020-08-15T09:48:17Z", "comment_text": "Yes, tests should go inst/test - I'd put those in test-gtable.r.  But I'd use png: ggsave(\"aspect_ratio_facet_null.png\", p1, width = 6, height = 6, dpi = 72), and maybe write a helper function ggtest that saves them in that format.\n(Sorry I don't have time at the moment to write the tests myself)"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE4NTUyNTA=", "comment_author": "BrianDiggs", "comment_created_date": "2020-08-19T19:09:50Z", "comment_text": "I've built on this.  You can build further by sending pull requests to the autoplot branch of my fork of ggplot2. https://github.com/BrianDiggs/ggplot2/tree/autoplot  This is the branch that is requested to be pulled in #229."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE4NTU0NjQ=", "comment_author": "gsk3", "comment_created_date": "2020-08-19T19:26:48Z", "comment_text": "Thanks Brian.\nBest,\nAri\nOn Fri, Aug 19, 2011 at 9:09 PM, BrianDiggs <\nreply@reply.github.com>wrote:\n\nI've built on this.  You can build further by sending pull requests to the\nautoplot branch of my fork of ggplot2.\nhttps://github.com/BrianDiggs/ggplot2/tree/autoplot  This is the branch\nthat is requested to be pulled in #229.\n\nReply to this email directly or view it on GitHub:\n#228 (comment)"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE4OTk4NzI=", "comment_author": "hadley", "comment_created_date": "2020-08-25T13:38:51Z", "comment_text": "Brian, would you mind making those few changes I suggested so I can pull?  Thanks!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MDAzNTI=", "comment_author": "BrianDiggs", "comment_created_date": "2020-08-25T14:33:52Z", "comment_text": "Sorry, was on vacation and working from home for a few days. I don't have a full development environment set up at home, so didn't want to try and make the changes there.  I've added a commit that has the requested changes and another."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MDI2MDQ=", "comment_author": "hadley", "comment_created_date": "2020-08-25T18:37:48Z", "comment_text": "Great - thanks Brian.  Will hopefully pull in the next week or so."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MTcyMzI=", "comment_author": "baptiste", "comment_created_date": "2020-08-26T21:49:50Z", "comment_text": "Hey \u2013 this all sounds amazing. Do you have minimal tests that do not involve complete plots so one can test the basic components themselves? I'm asking as I was working last week on a visualisation of collections of square matrices, where I had to reinvent a 2D layout, a colour scale guide, axes, etc. I'm curious to see if some parts of the new ggplot2 can be used independently, basically. Thanks!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MTc2MTU=", "comment_author": "kohske", "comment_created_date": "2020-08-26T22:44:08Z", "comment_text": "At this time, guide grobs need to be constructed via ggplot plot building, but you can easily extract the guide-box part.\nHere is an example:\np1 <- qplot(1:3, 1:3, colour=1:3) + guides(colour = \"colorbar\")\np1.data <- ggplot_build(p1)\np1.plot <- ggplot_gtable(p1, p1.data)\np1.guide <- p1.plot$grobs[[which(p1.plot$layout$name == \"guide-box\")]]\n\ngrid.draw(p1.guide)"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MTg4NjM=", "comment_author": "baptiste", "comment_created_date": "2020-08-27T06:28:53Z", "comment_text": "Thanks \u2013 is there a plan to extract this out of ggplot2 in the future?"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MTk3NzY=", "comment_author": "kohske", "comment_created_date": "2020-08-27T13:47:38Z", "comment_text": "Not sure but it is not difficult to write a wrapper function. colorstripGrob in gridExtra may be relevant."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MTk5MzM=", "comment_author": "hadley", "comment_created_date": "2020-08-27T14:42:01Z", "comment_text": "I think ideally a lot of this could would move into the scales package, but before that can happen the gtable needs to be moved out into its own package."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MTk5NzU=", "comment_author": "kohske", "comment_created_date": "2020-08-27T14:50:25Z", "comment_text": "Will gtable be merged in grid package (or gridExtra) ?"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MjA3MTg=", "comment_author": "hadley", "comment_created_date": "2020-08-27T18:03:28Z", "comment_text": "Probably it's own package."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE5MjIxMTE=", "comment_author": "baptiste", "comment_created_date": "2020-08-28T00:29:14Z", "comment_text": "Great \u2013 I'll have a look at the code in gtable and if I can I'll try to extract it in a self-contained independent package."}], "lubridate": [{"comment_id": "MDEyOklzc3VlQ29tbWVudDc0Mjc5MTk=", "comment_author": "garrettgman", "comment_created_date": "2020-08-01T13:56:12Z", "comment_text": "Vitalie,\nThank you. That looks amazing! I anticipate releasing the next update to\nlubridate at the end of August. I'll make sure your parser goes into\nit. (I'm defending a dissertation in between, hence the delay)\nThank you again,\nGarrett\nOn Wed, Aug 1, 2012 at 6:52 AM, Vitalie Spinu <\nreply@reply.github.com\n\nwrote:\nHi,\nI have rewritten the lubridate parser. It's not based on str_split anymore\nbut on gsub, which has a massive speed improvement and comes close to the\nspeed of as.POSIXct.\nI am often facing heterogeneous formats in a single vector, which is due\nto aggregation from different sources or just bad quality data which would\nhave dates like \"2011-12-31 12:59\", \"2010-01-01 12\", \"2010-01-01\" in the\nsame vector.  The new version of ymd and ydm_hms families can  handle\nheterogeneous formats.\nThere is new low level function parseDateTime on which all other functions\n(including hms) are based. I have documented extensively all the parser\nfunctions and added examples to each of them.\nHere is the brief illustration of new functionality (lubridate:: prefixes\nhadley/master version):\n> tt <- rep(as.character(Sys.time()), 10^5)\n> system.time(out <- lubridate::ymd_hms(tt)) ## strsplit is not an option\nUsing date format %Y-%m-%d.\n   user  system elapsed\n200.500   1.356 215.434\n> system.time(out <- ymd_hms(tt))\n100000 parsed in %Y-%m-%d-%H-%M-%S order\n   user  system elapsed\n  1.152   0.000   1.164\n\n> tt <- rep(\"3:3:3\", 10^5)\n> system.time(out <- lubridate:::hms(tt))\n   user  system elapsed\n 88.902   0.632  93.983\n> system.time(out <- hms(tt))\n   user  system elapsed\n  1.296   0.024   1.382\n\nComes close to as.POSIXct:\n> tt <- rep(as.character(Sys.time()), 10^6)\n> system.time(out <- as.POSIXct(tt, tz = \"UTC\"))\n   user  system elapsed\n 11.173   0.232  11.685\n> system.time(out <- ymd_hms(tt))\n1000000 parsed in %Y-%m-%d-%H-%M-%S order\n   user  system elapsed\n 11.576   0.152  12.479\nHeterogeneous formats:\n> x <- c(20100101120101, \"2009-01-02 12-01-02\", \"2009.01.03 12:01:03\",\n\"2009-1-4 12-1-4\",\n+        \"2009-1, 5 12:1, 5\", \"2009....1--6 - 12::1:6\", \"20090107 120107\",\n\"200901-08 1201-8\",\n+        \"10-01-09 12:01:09\", \"10-01-10 10:01:10 AM\", \"10-01-11 10:01:11\nPM\")\n> ymd_hms(x)\n1 parsed in %y-%m-%d-%H-%M-%S order\n5 parsed in %Y-%m-%d-%H-%M-%S order\n2 parsed in %y-%m-%d-%I-%M-%S-%p order\n3 parsed in %Y%m%d%H%M%S order\n [1] \"2010-01-01 12:01:01 UTC\" \"2009-01-02 12:01:02 UTC\" \"2009-01-03\n12:01:03 UTC\"\n [4] \"2009-01-04 12:01:04 UTC\" \"2009-01-05 12:01:05 UTC\" \"2009-01-06\n12:01:06 UTC\"\n [7] \"2009-01-07 12:01:07 UTC\" \"2009-01-08 12:01:08 UTC\" \"2010-01-09\n12:01:09 UTC\"\n[10] \"2010-01-10 10:01:10 UTC\" \"2010-01-11 22:01:11 UTC\"\nTruncated formats:\n> x <- c(\"2011-12-31 12:59:59\", \"2010-01-01 12:11\", \"2010-01-01 12\",\n\"2010-01-01\")\n> ymd_hms(x, missing = 3)\n1 parsed in %Y-%m-%d-%H-%M-%S order\n1 parsed in %Y-%m-%d-%H-%M order\n1 parsed in %Y-%m-%d-%H order\n1 parsed in %Y-%m-%d order\n[1] \"2011-12-31 12:59:59 UTC\" \"2010-01-01 12:11:00 UTC\" \"2010-01-01\n12:00:00 UTC\"\n[4] \"2010-01-01 00:00:00 UTC\"\n\n\n> x <- c(\"2011-12-31 12:59\", \"2010-01-01 12\", \"2010-01-01\")\n> ymd_hm(x, missing = 2)\n1 parsed in %Y-%m-%d-%H-%M order\n1 parsed in %Y-%m-%d-%H order\n1 parsed in %Y-%m-%d order\n[1] \"2011-12-31 12:59:00 UTC\" \"2010-01-01 12:00:00 UTC\" \"2010-01-01\n00:00:00 UTC\"\n\nFractional seconds.\n> options(digits.secs = 3)\n> x <- c(\"2011-12-31 12:59:59.23\", \"2010-01-01 12:11:10\")\n> ymd_hms(x, frac = TRUE)\n2 parsed in %Y-%m-%d-%H-%M-%OS order\n[1] \"2011-12-31 12:59:59.23 UTC\" \"2010-01-01 12:11:10.00 UTC\"\n\n> library(devtools)\n> install_github(\"lubridate\", \"vitoshka\")\n> options(digits.secs = 3)\n\n> x <- c(\"2011-12-31 12:59:59.23\", \"2010-01-01 12:11:10\")\n> ymd_hms(x, frac = TRUE)\n2 parsed in %Y-%m-%d-%H-%M-%OS order\n[1] \"2011-12-31 12:59:59.23 UTC\" \"2010-01-01 12:11:10.00 UTC\"\n\n> hms(\"3:3:3.34\", frac = TRUE)\n[1] 3 hours, 3 minutes and 3.34 seconds\nNew formats:\n> ymd_hms(\"10-12-01 01:01:01 AM\", \"10-12-01 01:01:01 PM\", 101010202020)\n2 parsed in %y-%m-%d-%I-%M-%S-%p order\n1 parsed in %y%m%d%H%M%S order\n[1] \"2010-12-01 01:01:01 UTC\" \"2010-12-01 13:01:01 UTC\" \"2010-10-10\n20:20:20 UTC\"\n\nWith all these goodies come some minor limitations. See docs for\nparseDateTime and examples in ymd_hms. These are mainly due to the fact\nthat parsing now is not ignoring the tail of the string, as strptime does.\nThat is the format must match exactly.\nThis pull fixes #100 and #98.\nYou can merge this Pull Request by running:\ngit pull https://github.com/vitoshka/lubridate parser\nOr you can view, comment on it, or merge it online at:\n#123\n-- Commit Summary --\n\nA complete rewrite of the lubridate parser.\nremove unnecessary sub-setting in new_period, period\nadjust test cases for new error message and new formats\nfirst take on  documentation\n... in parser functions can contain character as well as numeric vectors\nDoc tweaking.\ncorrectly handle train/no-train error messages + for efficiency reasons\nskip\nadded deprecation for internal function parse_date\nfixed bug in parseDateTime for train = NULL\nmany more examples and improved docs\nseparated formats have priority over collapsed + improved handling of\nseparators\nallow fractional seconds in Period class\na smarter training set selection + docs\nbetter treatment of truncated formats\ntest cases to accommodate new features\ndocumented lubridate_formats + other doc fixes\nre-roxygenise\nadd commented speed test to test-parsers.R\n\n-- File Changes --\nM INSPIRATIONS (85)\nM NAMESPACE (2)\nM R/parse.r (1219)\nM R/periods.r (5)\nM inst/tests/test-parsers.R (124)\nM man/Duration-class.Rd (40)\nM man/Interval-class.Rd (60)\nM man/Period-class.Rd (76)\nM man/Timespan-class.Rd (2)\nM man/am.Rd (2)\nM man/dst.Rd (6)\nM man/hm.Rd (13)\nM man/hms.Rd (22)\nM man/hour.Rd (2)\nA man/lubridate_formats.Rd (22)\nM man/minute.Rd (2)\nM man/month.Rd (2)\nM man/ms.Rd (20)\nA man/parseDateTime.Rd (185)\nM man/parse_date.Rd (44)\nM man/second.Rd (2)\nM man/tz.Rd (2)\nM man/week.Rd (2)\nM man/year.Rd (2)\nM man/ymd.Rd (78)\nM man/ymd_hms.Rd (91)\n-- Patch Links --\nhttps://github.com/hadley/lubridate/pull/123.patch\nhttps://github.com/hadley/lubridate/pull/123.diff\n\nReply to this email directly or view it on GitHub:\n#123"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDc0NDExNDM=", "comment_author": "vspinu", "comment_created_date": "2020-08-01T21:49:57Z", "comment_text": "Sure. Good luck with the defense! I will keep adding and revising in\nmeanwhile, as there is still plenty of room for improvement.\nBest,\nVitalie.\n\n\ngarrettgman reply@reply.github.com\non Wed, 1 Aug 2012 06:56:13 -0700 wrote:\n\nVitalie,\nThank you. That looks amazing! I anticipate releasing the next update to\nlubridate at the end of August. I'll make sure your parser goes into\nit. (I'm defending a dissertation in between, hence the delay)\nThank you again,\nGarrett"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDc3MjM4NTI=", "comment_author": "vspinu", "comment_created_date": "2020-08-14T12:11:07Z", "comment_text": "Hi Garrett,\nI know you must be just in the middle of your defence right now. Hope everything\nis going well.\nFor the record, here is a track of my recent parser rewrites. I have implemented\nmini regexp parser, so that a bunch of new functionality became possible: stamps,\narbitrary input formats and locales among others.\nSo here are the new features:\nSpeed:\nIt comes close to strptime and is considerably faster than as.POSIXct even for\nhomogeneous case. This is pretty much the bottom line for speed.\n> tt <- rep(as.character(Sys.time()), 1e6)\n> system.time(out <- as.POSIXct(tt, tz = \"UTC\"))\nuser  system elapsed \n11.216   0.196  11.920 \n\n> system.time(out <- ymd_hms(tt))\n1000000 parsed with %Y-%m-%d %H:%M:%S\nuser  system elapsed \n7.021   0.316   7.539 \nFor heterogeneous data is up to 5 times faster thank as.POSIXct:\n> tt <- rep(c(as.character(Sys.time()), as.character(Sys.Date())), 5e5)\n> system.time(out <- as.POSIXct(tt, tz = \"UTC\"))\nuser  system elapsed \n29.774   0.716  31.183 \n\n> system.time(out <- ymd_hms(tt, tz = \"UTC\", truncated = 3))\n500000 parsed with %Y-%m-%d\n500000 parsed with %Y-%m-%d %H:%M:%S\nuser  system elapsed \n9.652   0.440  10.479 \nArbitrary formats:\nx <- c(20100101120101, \"dsf 09-01-02 12-01-02 dff\", \"2009.01.03 12:01:03\",\n       \"2009-1-4 12-1-4\",\n       \"2009-1, 5 12:1, 5\",\n       \"200901-08 1201-08\",\n       \"2009 arbitrary 1 non-decimal 6 chars 12 in between 1 !!! 6\",\n       \"OR collapsed formats: 20090107 120107 (as long as prefixed with zeros)\",\n       \"Automatic wday, Thu, detection, 10-01-10 10:01:10 and p format: AM sdf\",\n       \"Created on 10-01-11 at 10:01:11 PM\")\n\n> ymd_hms(x)\n1 parsed with Automatic wday, %a, detection, %y-%m-%d %I:%M:%S and p format: %p sdf\n1 parsed with %Y%m%d%H%M%S\n1 parsed with %Y.%m.%d %H:%M:%S\n1 parsed with %Y-%m-%d %H-%M-%S\n1 parsed with %Y-%m, %d %H:%M, %S\n1 parsed with %Y%m-%d %H%M-%S\n1 parsed with %Y arbitrary %m non-decimal %d chars %H in between %M !!! %S\n1 parsed with OR collapsed formats: %Y%m%d %H%M%S (as long as prefixed with zeros)\n1 parsed with Created on %y-%m-%d at %I:%M:%S %p\n1 parsed with dsf %y-%m-%d %H-%M-%S dff\n[1] \"2010-01-01 12:01:01 UTC\" \"2009-01-02 12:01:02 UTC\" \"2009-01-03 12:01:03 UTC\"\n[4] \"2009-01-04 12:01:04 UTC\" \"2009-01-05 12:01:05 UTC\" \"2009-01-08 12:01:08 UTC\"\n[7] \"2009-01-06 12:01:06 UTC\" \"2009-01-07 12:01:07 UTC\" \"2010-01-10 10:01:10 UTC\"\n[10] \"2010-01-11 22:01:11 UTC\"\n\n\n\n> guess_formats(x, \"ymdT\")\n                                                                   ymdT \n                                                         \"%Y%m%d%H%M%S\" \n                                                                   ymdT \n                                            \"dsf %y-%m-%d %H-%M-%S dff\" \n                                                                   ymdT \n                                                    \"%Y.%m.%d %H:%M:%S\" \n                                                                   ymdT \n                                                    \"%Y-%m-%d %H-%M-%S\" \n                                                                   ymdT \n                                                  \"%Y-%m, %d %H:%M, %S\" \n                                                                   ymdT \n                                                      \"%Y%m-%d %H%M-%S\" \n                                                                   ymdT \n         \"%Y arbitrary %m non-decimal %d chars %H in between %M !!! %S\" \n                                                                   ymdT \n \"OR collapsed formats: %Y%m%d %H%M%S (as long as prefixed with zeros)\" \n                                                                   ymdT \n\"Automatic wday, %a, detection, %y-%m-%d %I:%M:%S and p format: %p sdf\" \n                                                                   ymdT \n                                   \"Created on %y-%m-%d at %I:%M:%S %p\" \n\nStamps:\n> y <- c('February 20th 1973',\n+        \"february  14, 2004\",\n+        \"01 3 2010\",\n+        \"1 3 10\",\n+        \"12/31/99\", \n+        \"DOB:12/11/00\", \n+        'Thu, 1 July 2004 22:30:00',\n+        \"1979-05-27 05:00:59\",\n+        '00/13/10',\n+        \"03:23:22 pm\")\n> D <- as.POSIXct(\"2012-08-13 11:37:53\", tz = \"UTC\")\n\n> stamp(y[[7]])(D)\nUsing: \"%a, %d %B %Y %H:%M:%S\"\n[1] \"Mon, 13 August 2012 11:37:53\"\n\n> cbind(y, unlist(lapply(y, function(x) stamp(x, quiet = TRUE)(D))))\ny                                                         \n[1,] \"February 20th 1973\"        \"August 13th 2012\"            \n[2,] \"february  14, 2004\"        \"August  13, 2012\"            \n[3,] \"01 3 2010\"                 \"08 13 2012\"                  \n[4,] \"1 3 10\"                    \"08 13 12\"                    \n[5,] \"12/31/99\"                  \"08/13/12\"                    \n[6,] \"DOB:12/11/00\"              \"DOB:08/13/12\"                \n[7,] \"Thu, 1 July 2004 22:30:00\" \"Mon, 13 August 2012 11:37:53\"\n[8,] \"1979-05-27 05:00:59\"       \"2012-08-13 11:37:53\"         \n[9,] \"00/13/10\"                  \"12/13/08\"                    \n[10,] \"03:23:22 pm\"               \"11:37:53 AM\"                 \n\nThere is still the \"th\" \"st\" etc problem. It's especially complicated as it is locale specific and strptime has no support for it. As a special case I might consider treating it separately for en_ locales.\nLocales:\n> x_CN <- \"\u661f\u671f\u4e8c 2012 \u516b\u6708 14 12:07:40 \u4e0b\u5348\"\n> ymd_hms(x_CN, locale = \"zh_CN.utf8\")\n 1 parsed with %A %Y %B %d %I:%M:%S %p\n[1] \"2012-08-14 12:07:40 UTC\"\n> guess_formats(x_CN, \"ymdT\", locale = \"zh_CN.utf8\")\n                     ymdT \n\"%A %Y %B %d %I:%M:%S %p\" \n\n> x_RO <- \"Ma 2012 august 14 11:28:30 \"\n> ymd_hms(x_RO, locale = \"ro_RO.utf8\")\n 1 parsed with %a %Y %B %d %H:%M:%S \n[1] \"2012-08-14 11:28:30 UTC\"\n\n> x_RU <- \"\u0412\u0442. 2012 \u0410\u0432\u0433\u0443\u0441\u0442 14 11:28:19 \"\n> x_RU2 <- \"\u0412\u0442. 2012 \u0430\u0432\u0433. 14 11:52:57 \"\n> ymd_hms(c(x_RU, x_RU2), locale = \"ru_RU.utf8\")\n 2 parsed with %a %Y %B %d %H:%M:%S \n[1] \"2012-08-14 11:28:19 UTC\" \"2012-08-14 11:52:57 UTC\"\n>\n\nIn addition to previous fixes this also fixes #101, #103"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIyNjcxNjAw", "comment_author": "jasonelaw", "comment_created_date": "2020-08-14T22:13:32Z", "comment_text": "I think this is more in line with your suggestions; not surprisingly it's simpler.  But it did require the %/% method."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNjcwNDU4Mw==", "comment_author": "vspinu", "comment_created_date": "2020-08-01T20:54:07Z", "comment_text": "Thanks! Of course, any cleanups and code simplifications are always welcome.\nI am afraid I don't quite follow what exactly you want to fix with respect to \"named arguments\".  Do you say that defGeneric should not contain named arguments?"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNjkxNTg3Mw==", "comment_author": "hadley", "comment_created_date": "2020-08-02T14:09:49Z", "comment_text": "Style wise I think that:\nsetMethod(\"as_date\", \"numeric\",\n  function (x, origin = lubridate::origin) {\n    as.Date(x, origin = origin)\n   }\n)\nis better than\nsetMethod(f = \"as_date\", signature = \"numeric\",\n            function (x, origin = lubridate::origin) {\n              as.Date(x, origin = origin)\n            })"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNjcwNzg3MQ==", "comment_author": "vspinu", "comment_created_date": "2020-08-01T21:06:50Z", "comment_text": "Nevermind. I see that #454 fixes those."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNjcwOTM5NQ==", "comment_author": "vspinu", "comment_created_date": "2020-08-01T21:12:30Z", "comment_text": "Oups, I got confused with all these overlapping PR's. This commit wasn't broken AFA travis is concerned. #449 is broken."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNjcwNzMzMQ==", "comment_author": "vspinu", "comment_created_date": "2020-08-01T21:04:38Z", "comment_text": "Looks good, but generated a bunch of doc warnings. Unless you have time to look at it  I will merge it as is and will fix those myself tomorrow."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNjczMTMzMw==", "comment_author": "vspinu", "comment_created_date": "2020-08-01T22:48:57Z", "comment_text": "I cannot find the reason for this check failure introduce by S3 export refactoring:\nR CMD check results\n1 error  | 2 warnings | 0 notes\nchecking examples ... ERROR\nRunning examples in \u2018lubridate-Ex.R\u2019 failed\nThe error most likely occurred in:\n\n> base::assign(\".ptime\", proc.time(), pos = \"CheckExEnv\")\n> ### Name: pretty_dates\n> ### Title: Computes attractive axis breaks for date-time data\n> ### Aliases: pretty_dates\n> ### Keywords: chron dplot utilities\n> \n> ### ** Examples\n> \n> x <- seq.Date(as.Date(\"2009-08-02\"), by = \"year\", length.out = 2)\n> # \"2009-08-02\" \"2010-08-02\"\n> pretty_dates(x, 12)\nError in get(as.character(FUN), mode = \"function\", envir = envir) : \n  object 'pretty.month' of mode 'function' was not found\nCalls: pretty_dates -> match.fun -> get\nExecution halted\nAny ideas?"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNjkxNjQ2Mg==", "comment_author": "hadley", "comment_created_date": "2020-08-02T14:11:52Z", "comment_text": "I see what the problem is - I'll fix it later in the week (currently busy at a conference)"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNzAyOTYwMw==", "comment_author": "hadley", "comment_created_date": "2020-08-02T20:15:50Z", "comment_text": "Should be good now.  The subcomponents of pretty are no longer exported, which is technically a breaking change. But it seems unlikely that they'd be used by anyone."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNjcwODM5OA==", "comment_author": "vspinu", "comment_created_date": "2020-08-01T21:08:39Z", "comment_text": "Perfect. Thanks."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNjcxMjMwMw==", "comment_author": "vspinu", "comment_created_date": "2020-08-01T21:23:51Z", "comment_text": "Thanks for this. The doc checks are failing because you have renamed the argument and didn't re-run devtools::document. Could you please re-base and fix that?"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNzAyOTM0Nw==", "comment_author": "jasonelaw", "comment_created_date": "2020-08-02T20:14:52Z", "comment_text": "@vspinu, how does this look? I'm no git expert so I didn't attempt to clean up the commits. They're a little messy."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIzNzIxMDAwNA==", "comment_author": "vspinu", "comment_created_date": "2020-08-03T11:18:00Z", "comment_text": "Yeh, a bit unclean but it's fine. Also a news entry should have been added. Nevermind, I will fix that."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDI0MDU2OTE1MA==", "comment_author": "vspinu", "comment_created_date": "2020-08-17T22:30:06Z", "comment_text": "parse_period_unit works on a vector of length one by design. For what you propose function must be vectorized.\nOne way is to go with relatively complex multi regexp matcher (see regexpr function in R) with perl style captures. An alternative is to implement the parser in C directly. I am favoring the latter because is likely to be more reliable and easier to extend."}], "stringr": [{"comment_id": "MDEyOklzc3VlQ29tbWVudDEyODEzNzgxMQ==", "comment_author": "hadley", "comment_created_date": "2020-08-05T20:28:29Z", "comment_text": "Oops, thanks!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDQxNjYwMjM2OQ==", "comment_author": "hadley", "comment_created_date": "2020-08-28T14:18:14Z", "comment_text": "Thanks!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDQxNjU5OTM5MA==", "comment_author": "hadley", "comment_created_date": "2020-08-28T14:11:41Z", "comment_text": "I'm not sure I want to make str_view() any more complicated. It might be better to submit this to regexplain ?"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDQxNjYyNTUwNA==", "comment_author": "jrnold", "comment_created_date": "2020-08-28T15:13:53Z", "comment_text": "No problem; that makes total sense. The issue for me was that the output of str_view did not play nicely with PDF in the R4DS solutions.\nThanks for pointing me to regexplain!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDQxMTA0Mjc1Mg==", "comment_author": "jonocarroll", "comment_created_date": "2020-08-07T12:43:36Z", "comment_text": "Tests can certainly be added to satisfy codecov if this is supported."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDQxNjU5ODc0MQ==", "comment_author": "hadley", "comment_created_date": "2020-08-28T14:09:52Z", "comment_text": "IMO it's better for to teach about why [[1]] is the right thing to do here."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDQxNTEzMTc0NQ==", "comment_author": "seanpor", "comment_created_date": "2020-08-22T18:26:02Z", "comment_text": "It says there is an issue with codecov/project!!!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDQxNTE5OTA2NQ==", "comment_author": "hadley", "comment_created_date": "2020-08-22T22:13:56Z", "comment_text": "Perfect, thanks!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDQxNjU5ODgxNQ==", "comment_author": "hadley", "comment_created_date": "2020-08-28T14:10:06Z", "comment_text": "Thanks!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDQxNjU5ODk1OQ==", "comment_author": "hadley", "comment_created_date": "2020-08-28T14:10:31Z", "comment_text": "Thanks!"}]}