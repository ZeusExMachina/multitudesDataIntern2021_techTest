{"ggplot2": [{"comment_id": "MDEyOklzc3VlQ29tbWVudDUwNzA5NzQ=", "comment_author": "hadley", "comment_created_date": "2020-04-11T15:09:05Z", "comment_text": "@wch Could you please add a note to NEWS and then merge? Thanks!"}], "lubridate": [{"comment_id": "MDEyOklzc3VlQ29tbWVudDE2Nzc2NTI4", "comment_author": "imanuelcostigan", "comment_created_date": "2020-04-22T10:50:36Z", "comment_text": "Hi Garrett, I think my commits above didn't actually action the change because at that point I thought Hadley had corrected me. But I think c.POSIXct should be using @export and not @S3method"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE2NzgzMDc1", "comment_author": "garrettgman", "comment_created_date": "2020-04-22T12:35:15Z", "comment_text": "Imanuel,\nI switched it back because c.POSIXct + @export was failing Cran's R Check, which means lubridate couldn't be uploaded to cran. Cran really wants S3 methods to be exported as S3methods.\nCan you give me an example of the actual bug you encounter when your code runs, so I can find another way to fix it? Thanks."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE2NzgzMjc5", "comment_author": "hadley", "comment_created_date": "2020-04-22T12:40:09Z", "comment_text": "S3 methods should definitely be exported with S3method() not export()"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE2MjY4NjE4", "comment_author": "vspinu", "comment_created_date": "2020-04-11T23:46:37Z", "comment_text": "Sorry Garrett. I am defending next week.  Have had no free day for quite long now. You know how it goes ;). I will have a deep look into the stuff next weekend for sure. Thanks for merging."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE2MjcxMDY3", "comment_author": "garrettgman", "comment_created_date": "2020-04-12T01:11:39Z", "comment_text": "Vitoshka, no problem at all. I just feel bad it took me three months to get back to this. For the record, I merged your pull request and implemented these changes in the commits that followed (all discussed in this thread):\n\nThe parsers propagate NA's and vectors of NA's just like as.POSIXct. If every element was an NA, they give the warning \"All failed to parse. No formats found.\" (unless quiet = TRUE)\nThe \"N parsed with %x%y%z\" messages no longer appear anywhere by default. A user can turn them on by setting options(lubridate.verbose = TRUE). The \"N failed to parse\" warnings still appear, except when n = everything, then the warning in 1) appears.\nI copied in ijlyttle's stamp.r and test-stamp.R files. Thanks Ian."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE2MjcxMzI0", "comment_author": "ijlyttle", "comment_created_date": "2020-04-12T01:24:02Z", "comment_text": "Hi guys,\nJust to make sure a potential bug does not get included, Garrett, if you have not already, can you consider this comment?\nI put a couple of tests in my copy of test-parsers.R. I can try to fix the bug, but it might take some time.\nThanks!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE2ODY4OTA4", "comment_author": "garrettgman", "comment_created_date": "2020-04-23T16:20:32Z", "comment_text": "Ian,\nI apologize. I merged the stamp.R and test-stamp.R files but missed test-parsers.R. Would you mind stating a new issue for this bug with an example? I'm not sure I understand what it is. Thanks!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE2MjcxMDc2", "comment_author": "garrettgman", "comment_created_date": "2020-04-12T01:12:05Z", "comment_text": "Thank you gnustats."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE2MjcxNDA0", "comment_author": "Unknown", "comment_created_date": "2020-04-12T01:27:16Z", "comment_text": "You're welcome.  It's my pleasure.  The language file will continuously\nupdated on the regular basis (probably.. every two months or by\nrequest).\nOn Thu, 2013-04-11 at 18:12 -0700, Garrett Grolemund wrote:\n\nThank you gnustats.\n\u2014\nReply to this email directly or view it on GitHub."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE3MDc3MTE1", "comment_author": "vspinu", "comment_created_date": "2020-04-26T14:21:31Z", "comment_text": "Hi Ian,\nI am a bit inclined not to ignore user supplied formats. Mainly for two reasons. First if the user explicitly supplies the formats then he/she probably knows what he/she is doing. Second, just picking the timezone from the inner parsing might result in surprising results when there are several ISO formats. For example:\n> ymd_hms(c(\"2012-03-04T05:06:07Z\", \"2012-03-04T05:06:07Z+0800\"))\n[1] \"2012-03-04 05:06:07 UTC\" \"2012-03-03 21:06:07 UTC\"\nWhereas right now the above parses correctly.\n> ymd_hms(c(\"2012-03-04T05:06:07Z\", \"2012-03-04T05:06:07Z+0800\"))\n[1] \"2012-03-04 05:06:07 UTC\" \"2012-03-03 21:06:07 UTC\"\nNote that in such a case the user might want to enforce some specific timezone, and if we ignore tz parameter there is no way left for the user to achieve that.\nSo I would prefer going through the path of least resistance, which, unless I miss something, also makes more sense as a user interface.\nPlease let me know what you think of  8a0ac74 (the content of #182)"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE3MDkzMjM5", "comment_author": "ijlyttle", "comment_created_date": "2020-04-26T18:46:52Z", "comment_text": "Hi Vitalie,\nI would like to raise an issue with the #182 approach. Consider that the string \"2012-03-04T05:06:07Z\" already implies a specific instant, expressed in UTC. Under #182. the expression ymd_hms(\"2012-03-04T05:06:07Z\", tz=\"America/Chicago\") returns \"2012-03-04 05:06:07 CST\", which is a different instant.\nIf we accept tz=\"America/Chicago\" as a valid input, I think the expression should return \"2012-03-03 23:06:07 CST\", which would be equivalent to with_tz(ymd_hms(\"2012-03-04T05:06:07Z\"), tz=\"America/Chicago\").\nI suppose the difference is the difference between force_tz() and with_tz() behavior. I favor the with_tz() behavior. If we accept this interpretation, there appear to be two possibilities to define the behavior:\n\nSupplying a string using an ISO-8601 format (implying UTC) and a non-UTC timezone represents a conflict because we are specifying timezone information differently, in two different places. The correct response is to return using UTC, ignore the tz argument, and supply a warning to this effect. This is what #179 does.\nSupplying a string using an ISO-8601 format (implying UTC) and a non-UTC timezone implies the intent of the user. The correct response is to parse the string into UTC, then to set the timezone according to the tz argument, as if to parse into UTC, then to apply the with_tz() function.\n\nI am fine with either approach, but if we choose the second, I would suggest issuing something less serious than a warning, perhaps a message:\nmessage(\"string parsed using ISO-8601 format; parsed as UTC, expressed using supplied timezone: \", tz)\n\nI realize that this seems to require a messier implementation, the inner parsing controlling some timezone behavior, but I think the motivation is valid.\nI keep an open mind and look forward to continuing the discussion."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE3MDk3OTA3", "comment_author": "vspinu", "comment_created_date": "2020-04-26T20:21:39Z", "comment_text": "I would like to raise an issue with the #182 approach. Consider that the string \"2012-03-04T05:06:07Z\"already implies a specific instant, expressed in UTC. Under #182. the expressionymd_hms(\"2012-03-04T05:06:07Z\", tz=\"America/Chicago\")returns\"2012-03-04 05:06:07 CST\"`, which is a different instant.\n\nThe correct instant depends on what you assume to be the correct\nindicator of the time zone (the Z in the format or the tz as specified\nby the user). I tend agree with you that Z format should have a priority\nover tz, after all this is the instant as it was recorded by original\nprogram.\n\n\nI suppose the difference is the difference between force_tz() and\nwith_tz() behavior. I favor the with_tz() behavior.\n\nPrecisely, we have to decide what is the semantics of tz argument that\nof with_tz or that of force_tz.\nCurrently documentation says:\n  tz: a character string that specifies the time zone with which to\n      parse the dates\n\nThere is no confusion if timezone is not part of the string. If not\nspecified it default to UTC.\n\nymd_hms(\"2012-03-04T05:06:07\", tz = \"America/Chicago\")\n[1] \"2012-03-04 05:06:07 CST\"\n\nIn this default case, the semantics is a bit closer to that of force_tz\n(we do not set UTC and then convert to CST, right).\nConsider mixed formats:\nymd_hms(c(\"2012-03-04T05:06:07-08:00\", \"2012-03-04T05:06:07\"), tz = \"America/Chicago\")\nWhatever semantics we choose for tz argument, it should be\nconsistent. That is, it should parse second string above as CST. This\ndoesn't happen in #179, so more work is needed.\nWhat I was proposing is an easy fix - force_tz. It's semantics is\nextremely simple - when tz is supplied set timezone irrespective of\nwhether Z format is present or not. Users can always choose not to\nsupply tz argument. This is why I didn't bother much.\nI also think your point (1) should be ruled out from the start because\nof the last example above. R keeps tz per vector, so you cannot have UTC\nfor the first instant and CST for the second.\nSo it's either yours (2), aka with_tz semantics, or #182 with force_tz\nsemantics. But, (2) is much more work, and we are lazy :)\nLet's see if we can achieve (2) without too much damage."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE3MDk5NjAy", "comment_author": "ijlyttle", "comment_created_date": "2020-04-26T20:57:57Z", "comment_text": "For the purpose of this comment, let me put aside the potential messiness in implementation to focus on understanding the issue.\nUp until now, the parser has not handled the case where the timezone is implied in the string. Thus the only sensible behavior has been force_tz().\nThe ISO-8601 formats all imply timezone is UTC, either explicity (Z) or implicitly (+07:30) with respect to UTC.\nGiven the possibility to have mixed (ISO-8601/non ISO-8601) string vectors, a behavior must be defined.\nPossibilities:\n\nin all cases force_tz() - the #182 approach\nif any member of the vector is ISO-8601, with_tz(), else force_tz()\nfigure out some way of splitting the vector into ISO-8601 and non-ISO-8601 parts, applying with_tz() or force_tz() as needed, combining.\n\nI appreciate the benefits of being lazy :), but if you guys would give me a few days to look at possibilities (2) and (3), I would appreciate it.\nSorry to keep changing the argument, but it seems to change as I try to understand it more...\nThanks"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE3MTc0NTM1", "comment_author": "ijlyttle", "comment_created_date": "2020-04-29T15:42:16Z", "comment_text": "Vitalie,\nCheck out my issue_178 branch (97f94ef). I think I might have solved the mixed-format issue (but I don't know if the solution is very efficient).\nThe essence is within .strptime(), where the global (user-supplied) timezone is passed to with_tz(). I suspect that .strptime is seeing a split version of the input vector, so I think this is how I am getting around the one-timezone-per-vector problem.\nGiven that supplying the timezone is OK, I have changed the warning to a message, and I have modified the test cases.\nI have also put in a test for the mixed-format case that passes. Please see if you can break it :).\n> ymd_hms(c(\"2012-03-04T05:06:07Z\", \"2001-02-03 04:05:06\"), tz=\"America/Chicago\")\nDate in ISO8601 format; converted timezone from UTC to America/Chicago.\n[1] \"2012-03-03 23:06:07 CST\" \"2001-02-03 04:05:06 CST\"\n\nIf this is OK, I will make another pull request.\nIan"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDE3MTgxOTkx", "comment_author": "ijlyttle", "comment_created_date": "2020-04-29T17:41:47Z", "comment_text": "Instead, please check out this commit (87a63b1), removing my initial fix of #178, and restoring vitoshka's fix for #177."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDk2NjE3OTI2", "comment_author": "vspinu", "comment_created_date": "2020-04-27T11:40:34Z", "comment_text": "@jonboiser, any chance you can have a look at this once again? The test is failing due to missing documentation. There a bunch of other issues with day doc, so I will fix this myself once this is merged.\nFor now, could you please add a bunch of corner cases tests and squash all the commits in one? Thanks."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDk3NjgwMTYz", "comment_author": "jonboiser", "comment_created_date": "2020-04-30T06:47:13Z", "comment_text": "I missed the part about the docs, and added a couple of lines.  I added just a simple test for the accessor and handful of more intricate cases in the setters test file."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDk3NzQxNzI5", "comment_author": "vspinu", "comment_created_date": "2020-04-30T11:11:43Z", "comment_text": "Oups. I cannot automatically merge it. Would you mind rebasing. Must be a minor conflict."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIwNDUzMDk3OQ==", "comment_author": "imanuelcostigan", "comment_created_date": "2020-04-01T19:19:37Z", "comment_text": "Btw see https://github.com/blog/2141-squash-your-commits for setting your repo up to squash commits rather than requiring contributors to do so"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIxMDUyNzQ4MA==", "comment_author": "vspinu", "comment_created_date": "2020-04-15T16:18:20Z", "comment_text": "Thanks. Sorry about that. It used to be correct. It must have been me when I sorted the contributors by number of commits :("}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIxMDU2NDA3NQ==", "comment_author": "ijlyttle", "comment_created_date": "2020-04-15T17:52:56Z", "comment_text": "No problem - thanks for including me!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIxNTk3NDAwNg==", "comment_author": "codecov-io", "comment_created_date": "2020-04-30T15:39:20Z", "comment_text": "Current coverage is 77.11%\n\nMerging #409 into master will not change coverage\n\n@@             master       #409   diff @@\n==========================================\n  Files            42         42          \n  Lines          2320       2320          \n  Methods           0          0          \n  Messages          0          0          \n  Branches          0          0          \n==========================================\n  Hits           1789       1789          \n  Misses          531        531          \n  Partials          0          0          \n\nPowered by Codecov. Last updated by 5c5c10a...87147b8"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDIxNTk5MTYwMA==", "comment_author": "vspinu", "comment_created_date": "2020-04-30T20:02:39Z", "comment_text": "Thanks!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDI5NzczMjczMw==", "comment_author": "randomgambit", "comment_created_date": "2020-04-27T14:37:53Z", "comment_text": "Hello there, following some interesting discussion with @krlmlr (tidyverse/hms#32), I post here my feedback on these changes (hoping that helps)\nI see @krlmlr's point of keeping hms as lightweight as possible, but consider the very frequent setting where someone works with intraday timestamped data, and needs to filter data between some business hours every day. Using hms(timestamp) > hms('09:30') is a natural way to do so. The horrible way to do so is to extract the time part of a timestamp (in string format) and compare to > '09:30:00'\nRight now, lubridate does not have a good support for time of day and that is why I think both packages are complementary. Ultimately, they could be combined into one (in the same fashion as in Pandas) but this is a matter of taste"}], "stringr": [{"comment_id": "MDEyOklzc3VlQ29tbWVudDI5NDg2NjU0Nw==", "comment_author": "hadley", "comment_created_date": "2020-04-18T14:41:35Z", "comment_text": "Thanks!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDI5NDg2Njg0Mg==", "comment_author": "hadley", "comment_created_date": "2020-04-18T14:42:27Z", "comment_text": "Thanks for the pull request, but currently I don't want to include infix string pasting in string."}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDI5NDg2NjM5OQ==", "comment_author": "hadley", "comment_created_date": "2020-04-18T14:41:08Z", "comment_text": "Thank you!!"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDM3ODg5MjcxNQ==", "comment_author": "pachevalier", "comment_created_date": "2020-04-05T10:35:57Z", "comment_text": "I've opened an issue in the readr package  : tidyverse/readr#826"}, {"comment_id": "MDEyOklzc3VlQ29tbWVudDQ4MTgzOTU2NQ==", "comment_author": "sastoudt", "comment_created_date": "2020-04-10T19:58:26Z", "comment_text": "Thank you for your patience! I've shortened and refocused the vignette, and removed the plyr dependency. I still have some stringr::str_wrap() and strwrap() issues, and the Travis CI check fails on R version 3.1.\nI'm happy to do another round of edits based on your feedback."}]}